{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a0af79c31b5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.instagram.com/explore/tags/{0}/?__a=1&max_id={1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_cursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mend_cursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'graphql'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hashtag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edge_hashtag_to_media'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'page_info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_cursor'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# value for the next page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "arr = []\n",
    "end_cursor = '' # empty for the 1st page\n",
    "tag = 'russia' # your tag\n",
    "page_count = 5 # desired number of pages\n",
    "for i in range(0, page_count):\n",
    "    url = \"https://www.instagram.com/explore/tags/{0}/?__a=1&max_id={1}\".format(tag, end_cursor)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    \n",
    "    end_cursor = data['graphql']['hashtag']['edge_hashtag_to_media']['page_info']['end_cursor'] # value for the next page\n",
    "    edges = data['graphql']['hashtag']['edge_hashtag_to_media']['edges'] # list with posts\n",
    "    \n",
    "    for item in edges:\n",
    "        arr.append(item['node'])\n",
    "    time.sleep(2) # insurence to not reach a time limit\n",
    "print(end_cursor) # save this to restart parsing with the next page\n",
    "with open('posts.json', 'w') as outfile:\n",
    "    json.dump(arr, outfile) # save to json\n",
    "\n",
    "with open('posts.json', 'r') as f:\n",
    "    arr = json.loads(f.read()) # load json data from previous step\n",
    "locations = []\n",
    "for item in arr:\n",
    "    shortcode = item['shortcode']\n",
    "    url = \"https://www.instagram.com/p/{0}/?__a=1\".format(shortcode)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    try:\n",
    "        location = data['graphql']['shortcode_media']['location']['name'] # get location for a post\n",
    "    except:\n",
    "         location = '' # if location is NULL\n",
    "    locations.append({'shortcode': shortcode, 'location': location})\n",
    "with open('locations.json', 'w') as outfile:\n",
    "    json.dump(locations, outfile) # save to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QVFBcVVzZ1BfNHUwUXpfX1JPSjF0WDA4U0JFX3l3SzZzZ002ay1vSHhZMlBzMjNtT0RIZ1BVdmE3ODdTTmJwQXBscV9OaTZVS05nMXl1NUpfLWtSbmk1Vg==\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# STEP 1: Scrap posts for a tag\n",
    "arr = []\n",
    "\n",
    "end_cursor = '' # empty for the 1st page\n",
    "tag = '原宿カフェ' # your tag\n",
    "page_count = 3 # desired number of pages\n",
    "\n",
    "for i in range(0, page_count):\n",
    "    url = \"https://www.instagram.com/explore/tags/{0}/?__a=1&max_id={1}\".format(tag, end_cursor)\n",
    "    r = requests.get(url)\n",
    "    try:\n",
    "        data = json.loads(r.text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    end_cursor = data['graphql']['hashtag']['edge_hashtag_to_media']['page_info']['end_cursor'] # value for the next page\n",
    "    edges = data['graphql']['hashtag']['edge_hashtag_to_media']['edges'] # list with posts\n",
    "    \n",
    "    for item in edges:\n",
    "       arr.append(item['node'])\n",
    "       \n",
    "    time.sleep(2) # insurence to not reach a time limit\n",
    "    \n",
    "print(end_cursor) # save this to restart parsing with the next page\n",
    "\n",
    "with open('posts.json', 'w') as outfile:\n",
    "    json.dump(arr, outfile) # save to json\n",
    "    \n",
    "# Step 2: Get locations for posts\n",
    "with open('posts.json', 'r') as f:\n",
    "    arr = json.loads(f.read()) # load json data from previous step\n",
    "    \n",
    "locations = []\n",
    "for item in arr:\n",
    "    shortcode = item['shortcode']\n",
    "    url = \"https://www.instagram.com/p/{0}/?__a=1\".format(shortcode)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    try:\n",
    "        data = json.loads(r.text)\n",
    "        try:\n",
    "            location = data['graphql']['shortcode_media']['location']['name'] # get location for a post\n",
    "        except:\n",
    "             location = '' # if location is NULL\n",
    "        locations.append({'shortcode': shortcode, 'location': location})\n",
    "    except:\n",
    "        location = ''\n",
    "        \n",
    "with open('locations.json', 'w') as outfile:\n",
    "    json.dump(locations, outfile) # save to json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('posts.json', 'r') as f:\n",
    "    arr = json.loads(f.read()) # load json data from previous step\n",
    "locations = []\n",
    "for item in arr:\n",
    "    shortcode = item['shortcode']\n",
    "    url = \"https://www.instagram.com/p/{0}/?__a=1\".format(shortcode)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    try:\n",
    "        location = data['graphql']['shortcode_media']['location']['name'] # get location for a post\n",
    "    except:\n",
    "         location = '' # if location is NULL\n",
    "    locations.append({'shortcode': shortcode, 'location': location})\n",
    "with open('locations.json', 'w') as outfile:\n",
    "    json.dump(locations, outfile) # save to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandasをインポート\n",
    "import pandas as pd\n",
    "\n",
    "#変換したいJSONファイルを読み込む\n",
    "df = pd.read_json(\"locations.json\")\n",
    "\n",
    "#CSVに変換して任意のファイル名で保存\n",
    "df.to_csv(\"locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# STEP 1: Scrap posts for a tag\n",
    "arr = []\n",
    "\n",
    "end_cursor = '' # empty for the 1st page\n",
    "tag = '歌舞伎町カフェ' # your tag\n",
    "page_count = 5 # desired number of pages\n",
    "\n",
    "for i in range(0, page_count):\n",
    "    url = \"https://www.instagram.com/explore/tags/{0}/?__a=1&max_id={1}\".format(tag, end_cursor)\n",
    "    r = requests.get(url)\n",
    "    try:\n",
    "        data = json.loads(r.text)\n",
    "        json.dumps(data)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    end_cursor = data['graphql']['hashtag']['edge_hashtag_to_media']['page_info']['end_cursor'] # value for the next page\n",
    "    edges = data['graphql']['hashtag']['edge_hashtag_to_media']['edges'] # list with posts\n",
    "    \n",
    "    for item in edges:\n",
    "        arr.append(item['node'])\n",
    "       \n",
    "    time.sleep(2) # insurence to not reach a time limit\n",
    "    \n",
    "print(end_cursor) # save this to restart parsing with the next page\n",
    "\n",
    "with open('posts.json', 'w') as outfile:\n",
    "    json.dump(arr, outfile) # save to json\n",
    "    \n",
    "# Step 2: Get locations for posts\n",
    "with open('posts.json', 'r') as f:\n",
    "    arr = json.loads(f.read()) # load json data from previous step\n",
    "    \n",
    "locations = []\n",
    "for item in arr:\n",
    "    shortcode = item['shortcode']\n",
    "    url = \"https://www.instagram.com/p/{0}/?__a=1\".format(shortcode)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    try:\n",
    "        data = json.loads(r.text)\n",
    "        try:\n",
    "            location = data['graphql']['shortcode_media']['location']['name'] # get location for a post\n",
    "        except:\n",
    "             location = '' # if location is NULL\n",
    "        locations.append({'shortcode': shortcode, 'location': location})\n",
    "    except:\n",
    "        location = ''\n",
    "        \n",
    "with open('locations.json', 'w') as outfile:\n",
    "    json.dump(locations, outfile) # save to json\n",
    "\n",
    "with open('posts.json', 'r') as f:\n",
    "    arr = json.loads(f.read()) # load json data from previous step\n",
    "locations = []\n",
    "for item in arr:\n",
    "    shortcode = item['shortcode']\n",
    "    url = \"https://www.instagram.com/p/{0}/?__a=1\".format(shortcode)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    try:\n",
    "        location = data['graphql']['shortcode_media']['location']['name'] # get location for a post\n",
    "    except:\n",
    "         location = '' # if location is NULL\n",
    "    locations.append({'shortcode': shortcode, 'location': location})\n",
    "with open('locations.json', 'w') as outfile:\n",
    "    json.dump(locations, outfile) # save to json\n",
    "\n",
    "#Pandasをインポート\n",
    "import pandas as pd\n",
    "\n",
    "#変換したいJSONファイルを読み込む\n",
    "df = pd.read_json(\"locations.json\")\n",
    "\n",
    "#CSVに変換して任意のファイル名で保存\n",
    "df.to_csv(\"locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
